{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83173,"databundleVersionId":9700231,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.nn.utils.rnn import pad_sequence\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', None)\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:45:20.948002Z","iopub.execute_input":"2024-12-15T19:45:20.948406Z","iopub.status.idle":"2024-12-15T19:45:27.202272Z","shell.execute_reply.started":"2024-12-15T19:45:20.948360Z","shell.execute_reply":"2024-12-15T19:45:27.201053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataframes = []\nfor i in tqdm(range(1, 11)):\n    train_dataframes.append(pd.read_csv(f'/kaggle/input/product-re-purchase-prediction/data-train/data-train/train_data_part_{i}.csv'))\n#train_dataframes.append(pd.read_csv(f'/kaggle/input/product-re-purchase-prediction/data-train/data-train/train_data_part_7.csv'))\ntrain_data = pd.concat(train_dataframes, ignore_index=True)\n\ndel train_dataframes\n\nproducts_data = pd.read_csv('/kaggle/input/product-re-purchase-prediction/data-train/data-train/products_data.csv', low_memory=False)\ntest_data = pd.read_csv('/kaggle/input/product-re-purchase-prediction/data-train/data-train/test_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:45:27.204133Z","iopub.execute_input":"2024-12-15T19:45:27.204623Z","iopub.status.idle":"2024-12-15T19:50:15.442030Z","shell.execute_reply.started":"2024-12-15T19:45:27.204588Z","shell.execute_reply":"2024-12-15T19:50:15.440456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hitrate@10 evaluation function\ndef hitrate_at_k(true_data: pd.DataFrame,\n                 predicted_data: pd.DataFrame,\n                 k: int = 10) -> float:\n    \"\"\"\n    This function calculates the hitrate at k for the recommendations.\n    It assesses how relevant our 10 product recommendations are.\n    In other words, it calculates the proportion of recommended products that are actually purchased by the customer.\n\n    Args:\n        true_data: a pandas DataFrame containing the true data\n            customer_id: the customer identifier\n            product_id: the product identifier that was purchased in the test set\n        predicted_data: a pandas DataFrame containing the predicted data\n            customer_id: the customer identifier\n            product_id: the product identifier that was recommended\n            rank: the rank of the recommendation. the rank should be between 1 and 10.\n        k: the number of recommendations to consider. k should be between 1 and 10.\n\n    Returns:\n        The hitrate at k\n    \"\"\"\n\n    data = pd.merge(left = true_data, right = predicted_data, how = \"left\", on = [\"customer_id\", \"product_id\"])\n    df = data[data[\"rank\"] <= k]\n    non_null_counts = df.groupby('customer_id')['rank'].apply(lambda x: x.notna().sum()).reset_index(name='non_null_count')\n    distinct_products_per_customer = data.groupby('customer_id')['product_id'].nunique().reset_index(name='distinct_product_count')\n    df = pd.merge(left = distinct_products_per_customer, right = non_null_counts, how = \"left\", on = \"customer_id\")\n    df[\"denominator\"] = [min(df.iloc[i].distinct_product_count,k) for i in range(len(df))]\n    df = df.fillna(0)\n    return (df[\"non_null_count\"]/df[\"denominator\"]).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:50:15.444076Z","iopub.execute_input":"2024-12-15T19:50:15.444465Z","iopub.status.idle":"2024-12-15T19:50:15.455495Z","shell.execute_reply.started":"2024-12-15T19:50:15.444422Z","shell.execute_reply":"2024-12-15T19:50:15.454287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data['date'] = pd.to_datetime(train_data['date'])\n\n# Add recency attribute\nlatest_date = train_data['date'].max()  # Find the latest date in the dataset\ntrain_data['recency'] = (latest_date - train_data['date']).dt.days  # Calculate days since last purchase\n\n# Group by customer_id and product_id to calculate quantity and most recent purchase\ncustomer_product_data = train_data.groupby(['customer_id', 'product_id']).agg({\n    'quantity': 'sum',\n    'recency': 'min'  # Minimum days since purchase (most recent)\n}).reset_index()\n\n# Normalize quantity and recency scores\ncustomer_product_data['quantity_score'] = customer_product_data['quantity'] / customer_product_data['quantity'].max()\ncustomer_product_data['recency_score'] = 1 - (customer_product_data['recency'] / customer_product_data['recency'].max())  # Recent = higher score\n\n# Merge frequency data into customer_product_data\nfrequency = train_data.groupby(['customer_id', 'product_id'])['transaction_id'].count().reset_index(name='frequency')\ncustomer_product_data = customer_product_data.merge(frequency, on=['customer_id', 'product_id'], how='left')\n\n# Fill any missing frequency values (if any product has no transactions counted, assume 0)\ncustomer_product_data['frequency'] = customer_product_data['frequency'].fillna(0)\n\n# Normalize frequency score\ncustomer_product_data['frequency_score'] = customer_product_data['frequency'] / customer_product_data['frequency'].max()\n\n# Define the set of popular items\npopular_items = {'Product_23971', 'Product_28633', 'Product_39751', 'Product_20421', 'Product_63301', 'Product_57942'}\n\n# Add a column to indicate if a product is popular\ncustomer_product_data['is_popular'] = customer_product_data['product_id'].isin(popular_items).astype(int)\n\nBest_alpha=0.03\nBest_beta=0.87\nBest_gamma=0.1\nBest_leverage=0.0019395677472984205\n\n# Recalculate the final score, adding leverage for popular items\ncustomer_product_data['final_score'] = (\n    Best_alpha * customer_product_data['quantity_score'] + \n    Best_beta * customer_product_data['frequency_score'] +\n    Best_gamma * customer_product_data['recency_score'] +\n    Best_leverage * customer_product_data['is_popular']  # Add leverage\n)\n\n# Rank products for each customer with unique ranks\ncustomer_product_data['rank'] = (\n    customer_product_data.sort_values(\n        by=['customer_id', 'final_score', 'quantity', 'product_id'], \n        ascending=[True, False, False, True]  # Sort order\n    ).groupby('customer_id').cumcount() + 1\n)\n\n# Filter only the top 10 items for each customer\ntop_10_per_customer = customer_product_data[customer_product_data['rank'] <= 10]\n\n# Sort by customer_id and rank to ensure proper order\ntop_10_recommendations = top_10_per_customer.sort_values(by=['customer_id', 'rank'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:50:15.458683Z","iopub.execute_input":"2024-12-15T19:50:15.459310Z","iopub.status.idle":"2024-12-15T19:54:12.287079Z","shell.execute_reply.started":"2024-12-15T19:50:15.459238Z","shell.execute_reply":"2024-12-15T19:54:12.285744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission file for \n\n# Keep only the top 10 recommendations for Households between 80001 and 100000\nprediction = top_10_recommendations[\n    top_10_recommendations.customer_id.isin(\n            [\n                f\"Household_{i}\" for i in range(80001,100001)\n            ]\n        )\n    ]\n\n# Print the solution\nprediction.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:54:12.288433Z","iopub.execute_input":"2024-12-15T19:54:12.288790Z","iopub.status.idle":"2024-12-15T19:54:12.425195Z","shell.execute_reply.started":"2024-12-15T19:54:12.288755Z","shell.execute_reply":"2024-12-15T19:54:12.423740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_and_format_prediction(df):\n    # Remplacement des caractères invalides dans les noms de colonnes\n    df.columns = df.columns.str.replace('+AF8-', '_', regex=False)\n    df = df.replace(r'\\+AF8-', '_', regex=True)\n\n    # Nettoyage des colonnes 'customer_id', 'product_id', et 'transaction_id'\n    if 'customer_id' in df.columns and df['customer_id'].dtype == 'object':\n        df['customer_id'] = df['customer_id'].str.extract('(\\d+)').fillna(11).astype(int)\n    if 'product_id' in df.columns and df['product_id'].dtype == 'object':\n        df['product_id'] = df['product_id'].str.extract('(\\d+)').fillna(11).astype(int)\n    if 'transaction_id' in df.columns and df['transaction_id'].dtype == 'object':\n        df['transaction_id'] = df['transaction_id'].str.replace(r'\\D', '', regex=True).fillna(11).astype(int)\n\n    df['id'] = df.index\n    df = df[['id'] + [col for col in df.columns if col != 'id']]\n\n    if 'customer_id' not in df.columns or 'product_id' not in df.columns:\n        raise ValueError(\"true_data must contain 'customer_id' and 'product_id' columns\")\n\n    # Grouper par customer_id et concaténer les valeurs des produits et des ranks\n    prediction_grouped = df.groupby('customer_id').agg({\n        'id': 'first',  # Prend la première valeur de 'id'\n        'product_id': lambda x: ','.join(map(str, x)),  # Concatène les product_id en chaîne de caractères\n        'rank': lambda x: ','.join(map(str, x))  # Concatène les ranks en chaîne de caractères\n    }).reset_index()\n\n    # Supprimer la colonne 'id' si elle existe\n    if 'id' in prediction_grouped.columns:\n        prediction_grouped = prediction_grouped.drop(columns=['id'])\n\n    # Filtrer les données\n    prediction_grouped = prediction_grouped[prediction_grouped['customer_id'] != 11]\n    prediction_grouped.insert(0, 'id', range(len(prediction_grouped)))\n\n       # Vérification des rangs et des doublons\n    for index, row in prediction_grouped.iterrows():\n        # Vérifier les ranks\n        ranks = list(map(int, row['rank'].split(',')))\n        if sorted(ranks) != list(range(1, 11)):  # Vérifie que les rangs sont distincts de 1 à 10\n            print(\"Doublon détecté. Les rangs doivent être distincts (de 1 à 10) pour chacun des 10 produits prédits pour un client.\\n\")\n            return None\n        # Vérifier les doublons de produits\n        products = row['product_id'].split(',')\n        if len(products) != len(set(products)):  # Si des doublons sont présents dans les produits\n            print(\"Doublon détecté. Il doit y avoir 10 produits différents par client.\\n\")\n            return None\n\n\n    return prediction_grouped\nprediction_grouped=process_and_format_prediction(prediction)\nprint(prediction_grouped)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:54:12.426670Z","iopub.execute_input":"2024-12-15T19:54:12.427073Z","iopub.status.idle":"2024-12-15T19:54:15.834956Z","shell.execute_reply.started":"2024-12-15T19:54:12.427038Z","shell.execute_reply":"2024-12-15T19:54:15.833811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a .csv file to submit on kaggle\n# A lancer en local sur votre ordinateur\nprediction_grouped.to_csv('/kaggle/working/submission_list.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T19:54:15.836351Z","iopub.execute_input":"2024-12-15T19:54:15.836747Z","iopub.status.idle":"2024-12-15T19:54:15.907613Z","shell.execute_reply.started":"2024-12-15T19:54:15.836709Z","shell.execute_reply":"2024-12-15T19:54:15.906441Z"}},"outputs":[],"execution_count":null}]}